{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, fixed, interactive\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Subject Age Group', 'Subject ID', 'GO / SC Num', 'Terry Stop ID',\n",
      "       'Stop Resolution', 'Weapon Type', 'Officer ID', 'Officer YOB',\n",
      "       'Officer Gender', 'Officer Race', 'Subject Perceived Race',\n",
      "       'Subject Perceived Gender', 'Reported Date', 'Reported Time',\n",
      "       'Initial Call Type', 'Final Call Type', 'Call Type', 'Officer Squad',\n",
      "       'Arrest Flag', 'Frisk Flag', 'Precinct', 'Sector', 'Beat'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "original_dataset = pd.read_csv('..\\\\data\\\\terry-stops.csv')\n",
    "print(original_dataset.columns) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Drop:\n",
    "+ Subject ID: Group-level statistics are of interest and not individual ones.\n",
    "+ GO/SC Num (General Order and Street Check Number):  this identifier relates report to parent. sometimes has a one-to-many relationship. \n",
    "\n",
    "NaN Swaps:\n",
    "+ 'Officer Squad', 'Initial Call Type', 'Final Call Type','Call Type', 'Precinct', 'Sector', 'Beat': 'NaN' -> 'Not Reported'\n",
    "\n",
    "String Swaps:\n",
    "+ Subject Perceived Gender: '-' -> 'Not Reported'\n",
    "+ Subject Reported Race: '-' -> 'Not Reported'\n",
    "+ Officer Gender: '-' -> 'Not Reported'\n",
    "+ Weapon Type: '-' -> 'Not Reported'\n",
    "+ unify some of the Race terms: multi-racial (remove \"two or more races\"), hispanic(remove \"hispanic or latino\"), Black (remove \"black or african american\")\n",
    "\n",
    "String Edits:\n",
    "+ Final Call Type: remove '--' prefix\n",
    "\n",
    "Datestamp:\n",
    "+ combine 'Reported Date' and 'Reported Time' to 'Reported Datestamp' in datetime format\n",
    "+ Drop 'Reported date' and 'Reported Time'\n",
    "\n",
    "Data\n",
    "+ arrest_flag, frisk_flag Y/N to 1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmath import isnan\n",
    "\n",
    "\n",
    "police_stops = original_dataset.drop(['Subject ID', 'GO / SC Num'], axis=1)\n",
    "police_stops.replace(to_replace='-', value='Not Reported', inplace=True)\n",
    "\n",
    "nan_swap_keys=['Officer Squad', 'Initial Call Type', 'Final Call Type','Call Type', 'Precinct', 'Sector','Beat']\n",
    "police_stops[nan_swap_keys] = police_stops[nan_swap_keys].fillna(value='Not Reported')\n",
    "\n",
    "police_stops['Officer Gender'] = police_stops['Officer Gender'].replace(to_replace='N', value='Not Reported')\n",
    "police_stops = police_stops.drop(police_stops[police_stops[\"Officer Gender\"]==\"Not Reported\"].index, axis=0) #drop them actually.\n",
    "\n",
    "# race description cleaning\n",
    "police_stops['Officer Race'] = police_stops['Officer Race'].apply(lambda x:x.replace(\"Two or More Races\",'Multi-Racial'))\n",
    "police_stops['Officer Race'] = police_stops['Officer Race'].apply(lambda x:x.replace(\"Hispanic or Latino\",'Hispanic'))\n",
    "police_stops['Officer Race'] = police_stops['Officer Race'].apply(lambda x:x.replace(\"Black or African American\",'Black'))\n",
    "police_stops['Officer Race'] = police_stops['Officer Race'].apply(lambda x:x.replace(\"Not Specified\",\"Not Reported\"))\n",
    "\n",
    "police_stops['Subject Perceived Race'] = police_stops['Subject Perceived Race'].apply(lambda x:x.replace(\"American Indian / Alaskan Native\",'American Indian/Alaskan Native'))\n",
    "\n",
    "police_stops['Final Call Type'] = police_stops['Final Call Type'].apply(lambda x:x.replace('--',''))\n",
    "\n",
    "police_stops['Reported Datestamp'] = police_stops['Reported Date'] + ' '+ police_stops['Reported Time']\n",
    "police_stops['Reported Datestamp'] = police_stops['Reported Datestamp'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S.%f0'))\n",
    "police_stops[\"Officer YOB\"].fillna(1900, inplace=True)\n",
    "police_stops[\"Officer YOB\"] = police_stops[\"Officer YOB\"].astype(int)\n",
    "police_stops = police_stops.drop(['Reported Date', 'Reported Time'], axis=1)\n",
    "\n",
    "# Add \"Officer Age (at Stop Date)\" column\n",
    "ONE_YEAR = datetime.timedelta(days=365)\n",
    "yobs = police_stops['Officer YOB'].astype(int).apply(lambda x:datetime.datetime(year=x, month=1, day=1))\n",
    "police_stops[\"Officer Age\"]= np.round((police_stops[\"Reported Datestamp\"] - yobs)/ONE_YEAR, 1)\n",
    "police_stops = police_stops.drop(police_stops[police_stops[\"Officer Age\"]>=80].index, axis=0) #drop super old\n",
    "SUBJECT_AGE_ORDER = [\"Not Reported\",\"1 - 17\",\"18 - 25\",\"26 - 35\",\"36 - 45\",\"46 - 55\",\"56 and Above\"]\n",
    "\n",
    "def bucketize_age(x) -> str: \n",
    "    x = round(x)\n",
    "    if 1>x<=17:\n",
    "        age = \"1 - 17\"\n",
    "    elif 18>x<=25:\n",
    "        age = \"18 - 25\"\n",
    "    elif 26>x<=35:\n",
    "        age = '26 - 35'\n",
    "    elif 36>x<=45:\n",
    "        age = '36 - 45'\n",
    "    elif 46>x<=55:\n",
    "        age = '46 - 55'\n",
    "    elif 56<x:\n",
    "        age = '56 and Above'\n",
    "    else:\n",
    "        age = 'Not Reported'\n",
    "    return age\n",
    "\n",
    "police_stops[\"Officer Age Group\"] = police_stops[\"Officer Age\"].apply(lambda x:bucketize_age(x))\n",
    "\n",
    "police_stops[\"Arrest Flag\"] = police_stops[\"Arrest Flag\"].map({\"Y\":True, \"N\":False})\n",
    "police_stops[\"Frisk Flag\"] = police_stops[\"Frisk Flag\"].map({\"Y\":True, \"N\":False})\n",
    "\n",
    "police_stops[\"Frisk Flag\"] = police_stops[\"Frisk Flag\"].fillna(value=False)\n",
    "police_stops[\"Arrest Flag\"] = police_stops[\"Arrest Flag\"].fillna(value=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "police_stops.head(5)\n",
    "police_stops[\"Officer Race\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-organize by Racial features: [Officer Race, Subject Perceived Race]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_race = police_stops.groupby(by=[\"Officer Race\", \"Subject Perceived Race\"]).count()\n",
    "frisks_race = by_race['Frisk Flag'].divide(police_stops.shape[0]).multiply(100).reset_index()\n",
    "arrests_race = by_race['Arrest Flag'].divide(police_stops.shape[0]).multiply(100).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the baseline demographics for officers, and subjects of Terry-Stops?\n",
    "- Stacked histogram visualizations that show officer/subject race, gender, and age groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,20))\n",
    "sns.violinplot(data=police_stops, x=\"Officer Age\", y=\"Officer Race\", hue=\"Officer Gender\", inner=\"box\", split=True, scale=\"count\", scale_hue=True)\n",
    "plt.xlim(right=70)\n",
    "plt.grid(visible=True)\n",
    "plt.title(\"Demographics of Officers who performed a 'Terry Stop'\")\n",
    "print(\"Distributions are scaled by count, within each racial description. therefore does not inidcate total headcount per group.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the violin plot that there are very few women. In fact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3)\n",
    "fig.set_size_inches(14,12)\n",
    "plt.subplot(1,3,1)\n",
    "plt.pie(police_stops[\"Officer Gender\"].value_counts(normalize=True), labels=[\"Male\", \"Female\"], autopct='%2.1f')\n",
    "ax[0].set_title('Gender Distribution of the Officers')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.pie(police_stops[police_stops[\"Officer Gender\"]=='M'][\"Officer Race\"].value_counts(normalize=True),\n",
    "    labels=list(police_stops[police_stops[\"Officer Gender\"]=='M'][\"Officer Race\"].value_counts(normalize=True).keys()),\n",
    "    autopct='%2.1f')\n",
    "ax[1].set_title('Self-Reported Races of Male Officers')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.pie(police_stops[police_stops[\"Officer Gender\"]=='F'][\"Officer Race\"].value_counts(normalize=True),\n",
    "    labels=police_stops[police_stops[\"Officer Gender\"]=='F'][\"Officer Race\"].value_counts(normalize=True).keys(),\n",
    "    autopct='%2.1f')\n",
    "ax[2].set_title('Self-Reported Races of Female Officers')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subjects involved in Terry Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=police_stops[[\"Subject Age Group\",\"Subject Perceived Race\",\"Subject Perceived Gender\"]].groupby(by=[\"Subject Perceived Race\",\"Subject Perceived Gender\"]).value_counts(normalize=True)\n",
    "a=a.reset_index().rename(columns={0:'Count'})\n",
    "fig = plt.figure(figsize=(14,5))\n",
    "sns.barplot(data=a, x='Subject Perceived Race', y=\"Count\", hue=\"Subject Age Group\", dodge=True,\n",
    "    order=police_stops[\"Subject Perceived Race\"].value_counts(normalize=True, sort=True, ascending=False).keys(),\n",
    "    hue_order=SUBJECT_AGE_ORDER)\n",
    "plt.xlabel(\"Subject Perceived Race in Decreasing Frequency Order\")\n",
    "plt.title(\"Ages of Subjects involved in 'Terry Stops'\")\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=police_stops[[\"Officer Age Group\",\"Officer Race\",\"Officer Gender\"]].groupby(by=[\"Officer Race\",\"Officer Gender\"]).value_counts(normalize=True)\n",
    "a=a.reset_index().rename(columns={0:'Count'})\n",
    "fig = plt.figure(figsize=(14,5))\n",
    "sns.barplot(data=a, x='Officer Race', y=\"Count\", hue=\"Officer Age Group\", dodge=True,\n",
    "    order=police_stops[\"Officer Race\"].value_counts(normalize=True, sort=True, ascending=False).keys(),\n",
    "    hue_order=SUBJECT_AGE_ORDER)\n",
    "plt.xlabel(\"Officer Race in Decreasing Frequency Order\")\n",
    "plt.title(\"Officer Ages involved in 'Terry Stops'\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interactive Pie-charts for arrests and race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pie_plot(df, officer_or_subject, dropdown) -> None:\n",
    "    if officer_or_subject=='Officer Race':\n",
    "        label = 'Subject Perceived Race'\n",
    "    else:\n",
    "        label = 'Officer Race'\n",
    "\n",
    "    pie_plot = plt.figure()\n",
    "    plt.title(f'Arrests: {label}')\n",
    "    pie_plot = plt.pie(x=df[df[officer_or_subject] == dropdown]['Arrest Flag'], labels=df[df[officer_or_subject] == dropdown][label], autopct='%2.1f')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "officer_race_dropdown = widgets.Dropdown(\n",
    "    options=arrests_race[\"Officer Race\"].unique(),\n",
    "    description=\"Officer Race\",\n",
    "    disabled=False,\n",
    "    value=arrests_race[\"Officer Race\"].unique()[0]\n",
    ")\n",
    "\n",
    "\n",
    "# figure = plt.figure()\n",
    "w = interact(pie_plot,df=fixed(arrests_race), officer_or_subject=fixed(\"Officer Race\"), dropdown=officer_race_dropdown)\n",
    "# display(widgets.VBox([officer_race_dropdown, w]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_race_dropdown = widgets.Dropdown(\n",
    "    options=arrests_race[\"Subject Perceived Race\"].unique(),\n",
    "    description=\"Subject Perceived Race\",\n",
    "    disabled=False,\n",
    "    value=arrests_race[\"Subject Perceived Race\"].unique()[0]\n",
    ")\n",
    "w=interact(pie_plot,df=fixed(arrests_race), officer_or_subject=fixed(\"Subject Perceived Race\"), dropdown=subject_race_dropdown)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weapons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What (if any) weapons are found?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pie_weapons(df, who, race, remove_none) -> None:\n",
    "\n",
    "    pie_plot = plt.figure()\n",
    "    plt.title(f'Weapons found: {who}: {race}')\n",
    "\n",
    "    if remove_none:\n",
    "        df = df.drop(df[df['Weapon Type']=='None'].index)\n",
    "        df = df.drop(df[df['Weapon Type']=='Not Reported'].index)\n",
    "\n",
    "    pie_plot = sns.barplot(y=100*df[df[who] == race]['Weapon Type'].value_counts(normalize=True, sort=True, ascending=False),\n",
    "        x=df[df[who] == race]['Weapon Type'].value_counts(normalize=True, sort=True, ascending=False).keys(),\n",
    "        )\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "\n",
    "toggle_who = widgets.ToggleButtons(\n",
    "    options=[\"Officer Race\", \"Subject Perceived Race\"],\n",
    "    disabled=False,\n",
    "    button_style='',\n",
    "    value=\"Officer Race\"\n",
    ")\n",
    "dropdown_race = widgets.Dropdown(\n",
    "    options=police_stops[toggle_who.value].unique(),\n",
    "    description=\"Race\",\n",
    "    disabled=False,\n",
    ")\n",
    "checkbox_remove_none = widgets.ToggleButtons(\n",
    "    options=[True, False],\n",
    "    value=True,\n",
    "    description='Show only those who had weapons?',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "#out = interact(pie_weapons, df=fixed(police_stops), who=toggle_who, race=dropdown_race, remove_none=checkbox_remove_none)\n",
    "\n",
    "out = widgets.interactive_output(pie_weapons, {\"df\":fixed(police_stops), \"who\":toggle_who, \"race\":dropdown_race, \"remove_none\":checkbox_remove_none})\n",
    "display(widgets.VBox([toggle_who,dropdown_race,checkbox_remove_none]),out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How Likely were you to get arrested, if?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_list = [\"Terry Stop ID\", \"Stop Resolution\", \"Officer ID\", \"Arrest Flag\", \"Reported Datestamp\",\"Initial Call Type\", \"Final Call Type\", \"Officer Age\", \"Officer YOB\", \"Officer Squad\", \"Beat\", \"Sector\", \"Precinct\"]\n",
    "feature_list = list(police_stops.drop(columns=remove_list).columns)\n",
    "outcome = police_stops[\"Arrest Flag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the per-feature likelihoods, assuming complete independence\n",
    "\n",
    "arrest_proportion=[]\n",
    "f=[]\n",
    "fv=[]\n",
    "fcl_proportion = []\n",
    "for feature in feature_list:\n",
    "    for cl in police_stops[feature].unique():\n",
    "        # probabilities = police_stops[police_stops[feature]==cl][\"Arrest Flag\"].value_counts(normalize=True) #not robust to cases where True=0\n",
    "        arrest_proportion.append(police_stops[police_stops[feature]==cl][\"Arrest Flag\"].sum()/police_stops[police_stops[feature]==cl][\"Arrest Flag\"].shape[0])\n",
    "        fcl_proportion.append(police_stops[police_stops[feature]==cl].shape[0]/police_stops.shape[0])\n",
    "        f.append(feature)\n",
    "        fv.append(cl)\n",
    "\n",
    "#create df in one go, somehow in this case slower than the alternates\n",
    "outcomes = pd.DataFrame.from_dict(data={\"Feature\":f, \"Feature Value\":fv, \"Arrest Proportion\":arrest_proportion, \"Feature Propotion\":fcl_proportion})\n",
    "outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = police_stops[feature_list].to_numpy() \n",
    "y = outcome.to_numpy()\n",
    "\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "encoder.feature_names = feature_list\n",
    "encoder.fit(X)\n",
    "X_enc = encoder.transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_enc, y, shuffle=True, random_state=19, train_size=0.75)\n",
    "\n",
    "## Categorical NB\n",
    "classifier_CNB = CategoricalNB()\n",
    "\n",
    "print(type(classifier_CNB).__name__)\n",
    "classifier_CNB.fit(X_train,y_train)\n",
    "print(f'Accuracy: {classifier_CNB.score(X_test, y_test):2.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RF\n",
    "classifier_RNF = RandomForestClassifier(n_estimators=100, random_state=19)\n",
    "print(type(classifier_RNF).__name__)\n",
    "classifier_RNF.fit(X_train,y_train)\n",
    "print(f'Accuracy: {classifier_RNF.score(X_test, y_test):2.3f}')\n",
    "\n",
    "permutation_importances_result = permutation_importance(classifier_RNF, X_test, y_test, n_repeats=19, random_state=19, n_jobs=2)\n",
    "permutation_feature_importances = pd.Series(permutation_importances_result.importances_mean, index=feature_list)\n",
    "\n",
    "impurity_importances = classifier_RNF.feature_importances_\n",
    "forest_importances = pd.Series(impurity_importances, index=feature_list)\n",
    "\n",
    "#plot impurity importance\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,10))\n",
    "ax = plt.subplot(2,1,1)\n",
    "sns.barplot(x=forest_importances.keys(), y=forest_importances.values)\n",
    "ax.set_title(\"Feature importances using mean decrease in tree impurity\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "#plot permutation importance\n",
    "ax = plt.subplot(2,1,2)\n",
    "sns.barplot(x=permutation_feature_importances.keys(), y=permutation_feature_importances.values)\n",
    "ax.set_title(\"Feature importances using permutation on RF model\")\n",
    "ax.set_ylabel(\"Mean accuracy decrease\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomly_generate_scenario(encoder, verbose=False, n=1):\n",
    "    features = encoder.categories_\n",
    "\n",
    "    feature_vector = np.zeros(shape=(n,encoder.n_features_in_), dtype=np.int32)\n",
    "    scenario=[]\n",
    "\n",
    "    for i, feature in enumerate(encoder.feature_names):\n",
    "        choice=np.random.randint(low=0, high=len(features[i]), size=n, dtype=np.int32)\n",
    "        feature_vector[...,i] = choice\n",
    "        scenario.append(features[i][choice])\n",
    "\n",
    "    if verbose:\n",
    "        print(feature_vector)\n",
    "        print(scenario)\n",
    "\n",
    "    return feature_vector, scenario\n",
    "\n",
    "def randomly_generate_scenario2(encoder, verbose=False, n=1):\n",
    "    n_features = encoder.n_features_in_\n",
    "\n",
    "    feature_vector = np.random.randint(low=np.zeros(shape=(n,n_features)),\n",
    "                high=[len(encoder.categories_[i]) for i in range(len(encoder.categories_))],\n",
    "                size=(n,n_features),\n",
    "                dtype=np.int32)\n",
    "                \n",
    "    scenario = encoder.inverse_transform(feature_vector)\n",
    "\n",
    "    return feature_vector, scenario\n",
    "\n",
    "def generate_scenario(example, encoder):\n",
    "    features = encoder.categories_\n",
    "    scenario=[]\n",
    "    for i in range(len(encoder.feature_names)):\n",
    "        s=[]\n",
    "        for n in range(example.shape[0]):\n",
    "            condition = int(example[n,i])\n",
    "            s.append(features[i][condition])\n",
    "        scenario.append(s)\n",
    "    return scenario\n",
    "\n",
    "def display_scenario(scenario, encoder):\n",
    "    features = encoder.feature_names\n",
    "\n",
    "    for i,condition in enumerate(scenario):\n",
    "        s = f'Feature: {features[i]} has condition: {condition}'\n",
    "        print(s)\n",
    "\n",
    "def infer(X, model):\n",
    "    y = model.predict(X)\n",
    "    return y\n",
    "\n",
    "def reverse_query(example, encoder, dataframe, verbose=False):\n",
    "    result=pd.DataFrame()\n",
    "    features = encoder.feature_names\n",
    "    for n in range(example.shape[0]):\n",
    "        stacked = \"\"\n",
    "        \n",
    "        for i in range(len(encoder.feature_names)):\n",
    "            condition = encoder.categories_[i][int(example[n,i])]\n",
    "\n",
    "            if isinstance(condition, str):\n",
    "                s = f'(dataframe[\"{features[i]}\"]==\"{condition}\")'\n",
    "            else:\n",
    "                s = f'(dataframe[\"{features[i]}\"]=={condition})'\n",
    "                \n",
    "            if i != encoder.n_features_in_-1:\n",
    "                s += ' & '\n",
    "            \n",
    "            stacked += s\n",
    "        stacked = 'dataframe[' + stacked + ']'\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Query: \", stacked)\n",
    "        temp = pd.eval(stacked, parser='pandas')\n",
    "\n",
    "        result = pd.concat([result,temp])\n",
    "\n",
    "    return result\n",
    "\n",
    "def reverse_dfquery(example:np.ndarray, encoder:OrdinalEncoder, dataframe:pd.DataFrame, verbose=False):\n",
    "\n",
    "    result=pd.DataFrame(columns=dataframe.columns)\n",
    "    features = encoder.feature_names\n",
    "    \n",
    "    for n in range(example.shape[0]):\n",
    "        \n",
    "        stacked = \"\"\n",
    "        s =\"\"\n",
    "        scenario = encoder.inverse_transform(example[n,:].reshape(1,-1))[0]\n",
    "\n",
    "        for i, condition in enumerate(scenario):\n",
    "\n",
    "            if (' ' in features[i]):\n",
    "                col = f'(`{features[i]}`=='\n",
    "            else:\n",
    "                col = f'({features[i]}=='\n",
    "\n",
    "            if isinstance(condition, str):\n",
    "                cond = f'\"{condition}\")'\n",
    "            else:\n",
    "                cond = f'{condition})'\n",
    "            \n",
    "            if i != encoder.n_features_in_-1:\n",
    "                s += col + cond +' and '\n",
    "            else:\n",
    "                s += col + cond\n",
    "            \n",
    "        stacked += s\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Query: \", stacked)\n",
    "            \n",
    "        temp = dataframe.query(expr=stacked, inplace=False)\n",
    "        result = pd.concat([result, temp])\n",
    "    \n",
    "    return result\n",
    "\n",
    "def check_results(predictions:np.ndarray, dataframe:pd.DataFrame):\n",
    "    historical_true_proportion = dataframe[\"Arrest Flag\"].sum()/dataframe.size\n",
    "    prediction_true_proportion = predictions.sum()/len(predictions)\n",
    "    return prediction_true_proportion, historical_true_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = np.array([[3., 8., 1., 7., 2., 1., 3., 0., 2.]])\n",
    "scenario_test_query = generate_scenario(test_query,encoder)\n",
    "display_scenario(scenario_test_query, encoder)\n",
    "predictions = infer(test_query, classifier_RNF)\n",
    "print(f'Classifer Suggest Arrest Flag: {[*predictions]}')\n",
    "rev_query = reverse_dfquery(test_query, encoder, police_stops, verbose=True)\n",
    "rev_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query_multi=X_enc[0:2,:]\n",
    "scenario_multi = generate_scenario(test_query_multi,encoder)\n",
    "display_scenario(scenario_multi, encoder)\n",
    "predictions = infer(test_query_multi, classifier_RNF)\n",
    "print(f'Classifer Suggests Arrest Flag: {[*predictions]}')\n",
    "rev_query = reverse_dfquery(test_query_multi, encoder, police_stops, verbose=True)\n",
    "rev_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits=0\n",
    "runs=0\n",
    "while hits <= 0:\n",
    "    example_query, scenario = randomly_generate_scenario2(encoder=encoder, verbose=False, n=1)\n",
    "    predictions = infer(example_query, classifier_RNF)\n",
    "    rev_query = reverse_dfquery(example_query, encoder, police_stops, verbose=False)\n",
    "    hits=rev_query.size\n",
    "    runs +=1\n",
    "\n",
    "display_scenario(scenario,encoder)\n",
    "prediction_true_proportion, historical_true_proportion = check_results(predictions, rev_query)\n",
    "print(f'Match(es) found after {runs:1} runs')\n",
    "print(f'Classifer Suggests Arrest Flag: {[*predictions]}')\n",
    "print(f'The results had a historical true percentage of {historical_true_proportion}')\n",
    "\n",
    "rev_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "\n",
    "#joblib for SKL per documentation\n",
    "#fname_me = '.\\\\models\\\\model_and_encoder.joblib'\n",
    "#joblib.dump((classifier_CNB, encoder),fname_me)\n",
    "\n",
    "#pickle for the dataframe\n",
    "#fname_db = '.\\\\data\\\\police_stops.pickle'\n",
    "#police_stops.to_pickle(path=fname_db)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d567de74db8d0c12a332ed002f590f9b562856e2675462b90f2b5fcf9ee7a14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
